{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airplane Crash Reasons Text Mining #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare tools ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import urllib.request # download files\n",
    "from collections import Counter\n",
    "import string\n",
    "########\n",
    "\n",
    "# text pre-processing\n",
    "import nltk \n",
    "from nltk.corpus import stopwords, wordnet # stop words\n",
    "from nltk.stem.snowball import SnowballStemmer # stemming\n",
    "from nltk import pos_tag, word_tokenize # identify POS tag, required by lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer # lemmatization\n",
    "########\n",
    "\n",
    "# feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "########\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "########\n",
    "\n",
    "# for Latent Dirichlet Allocation\n",
    "# import gensim\n",
    "# from gensim import corpora, models\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources to be downloaded with `nltk` downloader:**\n",
    "-  `stopwords` - stop words list\n",
    "-  `wordnet` - lemmatization\n",
    "-  `punkt` - tokenization\n",
    "-  `averaged_perceptron_tagger` - POS tag of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lee/Documents/Datasets for\n",
      "[nltk_data]     GitHub/kaggle_plane_crashes/...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lee/Documents/Datasets for\n",
      "[nltk_data]     GitHub/kaggle_plane_crashes/...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/lee/Documents/Datasets\n",
      "[nltk_data]     for GitHub/kaggle_plane_crashes/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/lee/Documents/Datasets for\n",
      "[nltk_data]     GitHub/kaggle_plane_crashes/...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory\n",
    "working_dir = \"/home/lee/Documents/Datasets for GitHub/kaggle_plane_crashes/\"\n",
    "\n",
    "# download to working directory\n",
    "nltk.download(['stopwords', 'wordnet', 'punkt', 'averaged_perceptron_tagger'], download_dir=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Inspect Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(working_dir+\"Airplane_Crashes_and_Fatalities_Since_1908.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (5268, 13)\n",
      "\n",
      "\n",
      "preview:\n",
      "         Date   Time                            Location  \\\n",
      "0  09/17/1908  17:18                 Fort Myer, Virginia   \n",
      "1  07/12/1912  06:30             AtlantiCity, New Jersey   \n",
      "2  08/06/1913    NaN  Victoria, British Columbia, Canada   \n",
      "3  09/09/1913  18:30                  Over the North Sea   \n",
      "4  10/17/1913  10:30          Near Johannisthal, Germany   \n",
      "\n",
      "                 Operator Flight #          Route                    Type  \\\n",
      "0    Military - U.S. Army      NaN  Demonstration        Wright Flyer III   \n",
      "1    Military - U.S. Navy      NaN    Test flight               Dirigible   \n",
      "2                 Private        -            NaN        Curtiss seaplane   \n",
      "3  Military - German Navy      NaN            NaN  Zeppelin L-1 (airship)   \n",
      "4  Military - German Navy      NaN            NaN  Zeppelin L-2 (airship)   \n",
      "\n",
      "  Registration cn/In  Aboard  Fatalities  Ground  \\\n",
      "0          NaN     1     2.0         1.0     0.0   \n",
      "1          NaN   NaN     5.0         5.0     0.0   \n",
      "2          NaN   NaN     1.0         1.0     0.0   \n",
      "3          NaN   NaN    20.0        14.0     0.0   \n",
      "4          NaN   NaN    30.0        30.0     0.0   \n",
      "\n",
      "                                             Summary  \n",
      "0  During a demonstration flight, a U.S. Army fly...  \n",
      "1  First U.S. dirigible Akron exploded just offsh...  \n",
      "2  The first fatal airplane accident in Canada oc...  \n",
      "3  The airship flew into a thunderstorm and encou...  \n",
      "4  Hydrogen gas which was being vented was sucked...  \n"
     ]
    }
   ],
   "source": [
    "print(\"dataframe shape: {}\".format(df.shape))\n",
    "print(\"\\n\")\n",
    "print(\"preview:\\n{}\".format(df.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
    "# see debate: https://github.com/pandas-dev/pandas/issues/11453\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M', errors='coerce').dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just curious about the overall deadliest planes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fatality count by airplane type, all years, both military and non-military operators:\n",
      " Type\n",
      "Douglas DC-3                 4793.0\n",
      "Antonov AN-26                1068.0\n",
      "Douglas DC-6B                1055.0\n",
      "Douglas C-47                 1046.0\n",
      "McDonnell Douglas DC-9-32     951.0\n",
      "Name: Fatalities, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"total fatality count by airplane type, all years, both military and non-military operators:\\n {}\"\\\n",
    "      .format(df.groupby(['Type'])['Fatalities'].sum().sort_values(ascending=False).nlargest()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Mining ##\n",
    "We now apply topic mining methods to the \"summary\" field. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Field of Interest ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During a demonstration flight, a U.S. Army flyer flown by Orville Wright nose-dived into the ground from a height of approximately 75 feet, killing Lt. Thomas E. Selfridge who was a passenger. This was the first recorded airplane fatality in history.  One of two propellers separated in flight, tearing loose the wires bracing the rudder and causing the loss of control of the aircraft.  Orville Wright suffered broken ribs, pelvis and a leg.  Selfridge suffered a crushed skull and died a short time later.\n",
      "\n",
      "First U.S. dirigible Akron exploded just offshore at an altitude of 1,000 ft. during a test flight.\n",
      "\n",
      "The first fatal airplane accident in Canada occurred when American barnstormer, John M. Bryant, California aviator was killed.\n",
      "\n",
      "The airship flew into a thunderstorm and encountered a severe downdraft crashing 20 miles north of Helgoland Island into the sea. The ship broke in two and the control car immediately sank drowning its occupants.\n",
      "\n",
      "Hydrogen gas which was being vented was sucked into the forward engine and ignited causing the airship to explode and burn at 3,000 ft..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in (list(range(5))):\n",
    "    print(df.loc[i, 'Summary']+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Missing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the Summary field contain any missing record? True\n"
     ]
    }
   ],
   "source": [
    "# pd.isnull(df_airplane_crashes['Summary'])\n",
    "print(\"Does the Summary field contain any missing record? {}\"\\\n",
    "      .format(df['Summary'].isnull().values.any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Text Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(working_dir)\n",
    "\n",
    "# replace NaN\n",
    "df['summary_filled'] = df['Summary'].fillna(value=' ')\n",
    "\n",
    "# remove punctuation\n",
    "df['removepunc'] = df['summary_filled'].str.replace('[^\\w\\s]', ' ')\n",
    "\n",
    "# lower casing\n",
    "df['lower'] = df['removepunc'].str.lower()\n",
    "\n",
    "# tokenize and lemmatize\n",
    "# adjective, satellite adjective, adverb, noun, verb = 'a', 's', 'r', 'n', 'v'\n",
    "def lemmatize_after_pos(summary):\n",
    "    lemma_summary = []\n",
    "    for word, tag in pos_tag(word_tokenize(summary)):\n",
    "        wntag = tag[0].lower()\n",
    "        wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "        lemma = WordNetLemmatizer().lemmatize(word, wntag) if wntag else word\n",
    "        lemma_summary.append(lemma)\n",
    "    return lemma_summary\n",
    "\n",
    "df['lemmatized'] = df['lower'].apply(lambda x: lemmatize_after_pos(x))\n",
    "\n",
    "# remove stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['removestop'] = df['lemmatized'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "df['processed_summary'] = df['removestop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demonstration', 'flight', 'u', 'army', 'flyer', 'fly', 'orville', 'wright', 'nose', 'dive', 'ground', 'height', 'approximately', '75', 'foot', 'kill', 'lt', 'thomas', 'e', 'selfridge', 'passenger', 'first', 'record', 'airplane', 'fatality', 'history', 'one', 'two', 'propeller', 'separate', 'flight', 'tear', 'loose', 'wire', 'brace', 'rudder', 'cause', 'loss', 'control', 'aircraft', 'orville', 'wright', 'suffer', 'broken', 'rib', 'pelvis', 'leg', 'selfridge', 'suffer', 'crushed', 'skull', 'die', 'short', 'time', 'later']\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0, 'processed_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stop\n",
    "df.drop(['summary_filled', 'removepunc', 'lower', 'removestop', 'lemmatized'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: fuel engine cause problem cabin crew run tank passenger thrust plane door explosion failure damage pressure experience rear open lead\n",
      "\n",
      "Topic #1: aircraft accident minute flight passenger report mile kill disappear later cause wreckage time military fly 30 day transport receive shoot\n",
      "\n",
      "Topic #2: ft 000 flight mountain crash 500 strike miss contact hold minute 11 10 16 lightning explode pattern 14 test crew\n",
      "\n",
      "Topic #3: aircraft pilot engine plane crash lose runway altitude failure power crew foot takeoff right fail ground turn control left hit\n",
      "\n",
      "Topic #4: crash route mountain en land heavy mile fog rain attempt sea airport weather poor aircraft mt hit near north visibility\n",
      "\n",
      "Topic #5: kill air helicopter aboard collision midair shoot dc force collide pilot jet atc rebel fighter cessna missile aircraft land avoid\n",
      "\n",
      "Topic #6: approach pilot flight condition weather crash aircraft crew runway altitude terrain fly poor instrument vfr failure low descend short descent\n",
      "\n",
      "Topic #7: aircraft control loss failure crash result wing flight ice turbulence stall thunderstorm cause severe water lead nose pitch helicopter fatigue\n",
      "\n",
      "Topic #8: plane crash cargo land landing aircraft airport attempt runway takeoff shortly engine make emergency flame approach cause strike field crew\n",
      "\n",
      "Topic #9: steep dive feather center set improperly gravity attemping stick load gust prop horizon shot santa box lock weight artificial engage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message+\"\\n\")\n",
    "    \n",
    "# Use tf (raw term count) features for LDA.\n",
    "# print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(df['processed_summary']\\\n",
    "                                 .apply(lambda summary_token_list: \" \".join(summary_token_list)))\n",
    "\n",
    "print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\" % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\\\n",
    "                                learning_method='online',\\\n",
    "                                learning_offset=50.,\\\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common causes of plane crash identified: engine failure, explosion, weather condition (fog, lightning), collision. Someone with more aviation experience will have a better understanding of the generated results."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
